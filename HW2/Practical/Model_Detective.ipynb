{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1><b>Comprehensive Regularization Analysis to Combat Overfitting</b></h1></center>"
      ],
      "metadata": {
        "id": "Xv2P0_nLUYcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction**\n",
        "In this exercise, we focus on time-series forecasting using the Electricity Transformer Dataset (ETT)—a non-stationary, seasonally varying dataset for predicting electricity consumption 24–96 hours ahead—with a small Transformer encoder that uses a large input window and no dropout or regularization, making it highly prone to **overfitting**. To address this, we must deeply analyze why each **regularization** method works, how different regularizers interact, and how to diagnose and correct overfitting in real-world cases."
      ],
      "metadata": {
        "id": "9aR84gXjUkfF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plan**\n",
        "1. **Diagnostic Analysis**: Perform an extensive diagnostic analysis on a severely overfitted pre-trained model using training/validation curves, weight distributions, activations, gradients, and saliency maps.  \n",
        "2. **Implement & Compare Regularizers**: Implement and evaluate at least eight regularization methods (e.g., L1/L2, Dropout variants, Normalization, Early Stopping, Augmentation) using accuracy, generalization gap, cost, and visual analyses.  \n",
        "3. **Deep Analytical Investigation**: Address key research questions on Dropout failure modes, ablation studies, empirical bias-variance decomposition, and generalization vs. model complexity."
      ],
      "metadata": {
        "id": "fS4Vtpg2UlLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "JQa6kXKdm-fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time, datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import urllib.request\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "DTpssbIUm-zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\\n\")"
      ],
      "metadata": {
        "id": "SaakAe1EnFZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading and Normalization Section"
      ],
      "metadata": {
        "id": "-G8Ad82Ch2n0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Load the ETTh1 dataset (download if not available)\n",
        "# dataset_path = './data/ETTh1.csv'\n",
        "# hint: you can use urllib.request.urlretrieve for downloading if the file doesn't exist\n",
        "\n",
        "# TODO: Apply proper normalization for time series data\n",
        "# hint: use z-score normalization (mean=0, std=1) with StandardScaler from sklearn\n",
        "\n",
        "dataset_path = './data/ETTh1.csv'\n",
        "train_dataset = None\n",
        "test_dataset = None\n",
        "train_subset = None\n",
        "\n",
        "# TODO: Create train_dataset and test_dataset using your custom dataset class or DataLoader logic\n",
        "# hint: split the dataset into train (80%) and test (20%)\n",
        "\n",
        "\n",
        "# Use a fraction of the training set to induce overfitting.\n",
        "# TODO: Use only ~15% of the training data to simulate overfitting\n",
        "# hint: random subset selection using torch.randperm or random.sample\n",
        "\n"
      ],
      "metadata": {
        "id": "Il3vB9kFUZIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the DataLoader for the training subset"
      ],
      "metadata": {
        "id": "7ZOfnGzljBI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = None  #batch_size=32\n",
        "test_loader = None   #batch_size=32\n",
        "\n",
        "\n",
        "# TODO: Read feature names from the dataset (remove 'date' column)\n",
        "feature_names = None\n",
        "\n",
        "print(f\"Dataset: ETTh1\")\n",
        "print(f\"Training samples: {len(train_subset) if train_subset else 'N/A'} (~15% of train dataset)\")\n",
        "print(f\"Test samples: {len(test_dataset) if test_dataset else 'N/A'}\")\n",
        "print(f\"Features: {', '.join(feature_names) if feature_names else 'N/A'}\")\n",
        "print(f\"Window size: 336, Forecast horizon: 24\\n\")\n"
      ],
      "metadata": {
        "id": "CFuvGMtDjBl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base Transformer Model\n",
        "\n"
      ],
      "metadata": {
        "id": "C9IOrLYskyTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBaseModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x.transpose(0, 1)).transpose(0, 1)\n",
        "        x = self.fc_out(self.relu(x[:, -1, :]))\n",
        "        return x"
      ],
      "metadata": {
        "id": "T0bVaMP2ky7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer With Dropout"
      ],
      "metadata": {
        "id": "52RsdmfEltev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerWithDropout(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=1, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout_rate),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "        # TODO: Add dropout layer for regularization\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Apply dropout\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x.transpose(0, 1)).transpose(0, 1)\n",
        "        x = self.relu(x[:, -1, :])\n",
        "        x = self.fc_out(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "N_Erzlutlt27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transformer With BatchNorm"
      ],
      "metadata": {
        "id": "bu8V6DMXmOIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerWithBatchNorm(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        # TODO: Add a Batch Normalization layer\n",
        "        self.bn = None\n",
        "\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(d_model, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO: Apply batch normalization on the embedded features\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer_encoder(x.transpose(0, 1)).transpose(0, 1)\n",
        "        x = self.fc_out(self.relu(x[:, -1, :]))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4mfp5ql2mOkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training and Evaluation Functions"
      ],
      "metadata": {
        "id": "er99AW_9nN3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device, l1_lambda=0.0):\n",
        "    model.train()\n",
        "    total_loss, total_mae, total = 0, 0, 0\n",
        "    start_time = time.time()\n",
        "    for inputs, targets in loader:\n",
        "        # TODO\n",
        "        if l1_lambda > 0:\n",
        "            # TODO: Compute L1 regularization term and add it to the loss\n",
        "            pass\n",
        "        # TODO: Backward pass and optimizer step\n",
        "        # TODO: Accumulate loss and MAE for statistics\n",
        "        total += inputs.size(0)\n",
        "    epoch_time = time.time() - start_time\n",
        "    # TODO: Return average loss, MAE, and epoch time\n",
        "    pass\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, total_mae, total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            # TODO\n",
        "            total += inputs.size(0)\n",
        "    # TODO: Return average loss and MAE\n",
        "    pass\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, epochs=10, l1_lambda=0.0):\n",
        "    model = model.to(device)\n",
        "    train_losses, test_losses, train_maes, test_maes = [], [], [], []\n",
        "    train_times = []\n",
        "    for epoch in range(epochs):\n",
        "        # TODO\n",
        "        train_loss, train_mae, epoch_time =\n",
        "        test_loss, test_mae =\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "        train_maes.append(train_mae)\n",
        "        test_maes.append(test_mae)\n",
        "        train_times.append(epoch_time)\n",
        "        if (epoch + 1) % 4 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"  Train Loss: {train_loss:.4f}, Train MAE: {train_mae:.4f}\")\n",
        "            print(f\"  Test Loss: {test_loss:.4f}, Test MAE: {test_mae:.4f}\")\n",
        "            print(f\"  Generalization Gap (MAE): {test_mae - train_mae:.4f}\")\n",
        "    total_time = sum(train_times)\n",
        "    # TODO: Compute total training time and return all metrics\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "sn7f1_X8nOQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiments"
      ],
      "metadata": {
        "id": "X2XhleiAp_ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store all results\n",
        "results = {}\n",
        "\n",
        "# Check input dimensions and data shapes\n",
        "data = pd.read_csv(dataset_path).drop(columns=['date'])\n",
        "input_dim = data.shape[1]\n",
        "print(f\"Detected input dimension: {input_dim}\")\n",
        "for batch_x, batch_y in train_loader:\n",
        "    print(f\"Input shape: {batch_x.shape}, Target shape: {batch_y.shape}\")\n",
        "    break\n",
        "\n",
        "\n",
        "# Experiment 1: Base Model (No Regularization)\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 1: Base Model (No Regularization)\")\n",
        "print(\"=\" * 70)\n",
        "model1 = TransformerBaseModel(input_dim=input_dim)\n",
        "criterion1 = nn.MSELoss()\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "results['Base Model'] = train_model(model1, train_loader, test_loader, criterion1, optimizer1)\n",
        "base_time = results['Base Model'][4]\n",
        "\n",
        "\n",
        "# Experiment 2: L1 Regularization\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 2: L1 Regularization (λ=0.0001)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize model, criterion, optimizer\n",
        "# TODO: Train model with l1_lambda argument\n",
        "# l1_time = results['L1 Regularization'][4]\n",
        "\n",
        "\n",
        "\n",
        "# Experiment 3: L2 Regularization (Weight Decay)\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 3: L2 Regularization (λ=0.01)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize model, criterion, optimizer (with weight_decay)\n",
        "# TODO: Train model using train_model()\n",
        "# l2_time = results['L2 Regularization'][4]\n",
        "\n",
        "\n",
        "# Experiment 4: Elastic Net (L1 + L2)\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 4: Elastic Net (L1=0.0001, L2=0.01)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize model, criterion, optimizer (with both L1 and L2 regularization)\n",
        "# TODO: Train and save results in 'Elastic Net'\n",
        "# elastic_time = results['Elastic Net'][4]\n",
        "\n",
        "\n",
        "\n",
        "# Experiment 5: Dropout\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 5: Dropout (rate=0.5)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize TransformerWithDropout model\n",
        "# TODO: Define loss, optimizer and train\n",
        "# dropout_time = results['Dropout'][4]\n",
        "\n",
        "\n",
        "# Experiment 6: Batch Normalization\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 6: Batch Normalization\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize TransformerWithBatchNorm model\n",
        "# TODO: Define loss, optimizer and train\n",
        "# bn_time = results['BatchNorm'][4]\n",
        "\n",
        "\n",
        "# Experiment 7: Early Stopping\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 7: Early Stopping (patience=3)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize model, criterion, optimizer\n",
        "# TODO: Implement training loop with early stopping logic\n",
        "# TODO: Save final results in results['Early Stopping']\n",
        "# early_time = total_time\n",
        "\n",
        "\n",
        "# Experiment 8: Gaussian Noise (Data Augmentation)\n",
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 8: Gaussian Noise (σ=0.1)\")\n",
        "print(\"=\" * 70)\n",
        "# TODO: Initialize model, criterion, optimizer\n",
        "# TODO: Implement training loop that adds Gaussian noise to inputs\n"
      ],
      "metadata": {
        "id": "Qeo628ikp_7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Training and Validation Loss/MAE Curves\n",
        "\n"
      ],
      "metadata": {
        "id": "x8c87Q72r93V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC: Training and Validation Curves\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TODO: Retrieve training results for the Base Model from the 'results' dictionary\n",
        "# TODO: Extract train_losses, test_losses, train_maes, and test_maes from 'data'\n",
        "\n",
        "# TODO: Create two subplots (1 row, 2 columns)\n",
        "# TODO: Plot training and validation loss curves on ax1\n",
        "# TODO: Set axis labels, title, legend, and grid for ax1\n",
        "\n",
        "# TODO: Plot training and validation MAE curves on ax2\n",
        "# TODO: Set axis labels, title, legend, and grid for ax2\n",
        "\n",
        "# TODO: Adjust layout and save the figure as 'loss_mae_curves.png'\n",
        "print(\"\\n✓ Loss and MAE curves saved as 'loss_mae_curves.png'\")\n",
        "\n",
        "# TODO: Compute final_train_mae, final_test_mae, and overfitting_gap\n",
        "# TODO: Print the overfitting analysis summary\n",
        "print(\"  Interpretation: Large gap indicates overfitting; model memorizes training data.\")\n"
      ],
      "metadata": {
        "id": "zapPvq9Ur-Ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weight Distribution Analysis"
      ],
      "metadata": {
        "id": "NBe1D1xLsx3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weights(model):\n",
        "    # TODO\n",
        "    pass\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC: Weight Distribution\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TODO: Extract weights from the trained base model using get_weights()\n",
        "\n",
        "# TODO: Plot a histogram of weight values\n",
        "\n",
        "# TODO: Save the figure as 'weight_distribution.png'\n",
        "print(\"\\n✓ Weight distribution saved as 'weight_distribution.png'\")\n",
        "\n",
        "# TODO: Compute and print mean and standard deviation of the weights\n",
        "print(\"  Interpretation: Large weights or high variance may indicate overfitting.\")\n"
      ],
      "metadata": {
        "id": "1fUaYDqosyNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Activation Distribution Analysis"
      ],
      "metadata": {
        "id": "wrNdh7HItIsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_activations(model, loader, device):\n",
        "    model.eval()\n",
        "    activations = []\n",
        "    # TODO\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in loader:\n",
        "            # TODO\n",
        "            pass\n",
        "\n",
        "    # TODO: Flatten and concatenate all captured activations into one numpy array\n",
        "    pass\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC: Activation Distribution\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TODO: Extract activations from the trained base model using get_activations()\n",
        "\n",
        "# TODO: Plot a histogram of activations\n",
        "\n",
        "# TODO: Save the figure as 'activation_distribution.png'\n",
        "print(\"\\n✓ Activation distribution saved as 'activation_distribution.png'\")\n",
        "\n",
        "# TODO: Compute mean and standard deviation of activations\n",
        "# TODO: Print activation statistics and interpretation\n",
        "print(\"  Interpretation: Large or highly concentrated activations may indicate overfitting.\")\n"
      ],
      "metadata": {
        "id": "SB-RfCI7tJbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Flow Analysis"
      ],
      "metadata": {
        "id": "-5jNqSPAt3qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient_flow(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    grad_norms = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        # TODO\n",
        "\n",
        "        # TODO: Loop through model parameters and record gradient norms\n",
        "        # Append (parameter_name, gradient_norm) to grad_norms list\n",
        "        break\n",
        "\n",
        "    # TODO: Return list of (name, norm) tuples\n",
        "    pass\n",
        "\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC: Gradient Flow\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# TODO: Define loss function (criterion)\n",
        "# TODO: Compute gradient flow using the trained model and test loader\n",
        "\n",
        "print(\"\\nGradient Norms:\")\n",
        "# TODO: Loop through grad_norms and print parameter name and gradient norm\n",
        "\n",
        "# TODO: Extract gradient norm values into a list\n",
        "# TODO: Plot histogram of gradient norms\n",
        "\n",
        "# TODO: Save the figure as 'gradient_flow.png'\n",
        "print(\"\\n✓ Gradient flow distribution saved as 'gradient_flow.png'\")\n",
        "\n",
        "# TODO: Compute mean and standard deviation of gradient norms\n",
        "# TODO: Print summary statistics and interpretation\n",
        "print(\"  Interpretation: Very small (vanishing) or large (exploding) gradients may indicate training issues or overfitting.\")\n"
      ],
      "metadata": {
        "id": "tarHEps6t4DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saliency Maps Analysis"
      ],
      "metadata": {
        "id": "4zRyIzK3ucFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: For simplicity, this exercise focuses on predicting only the *next* time step. However, this model is designed to analyze feature importance across *all* time steps to enable clearer saliency visualization and full-sequence gradient flow.\n",
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC: Saliency Map Analysis (Enhanced Model for Clear Patterns)\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def plot_saliency_map(model, loader, device, filename='saliency_map.png', title='Saliency Map'):\n",
        "    model.eval()\n",
        "    # TODO\n",
        "    pass\n",
        "\n",
        "    # TODO: Create a heatmap visualization for the first few samples\n",
        "    print(f\"\\n✓ Saliency map saved as '{filename}'\")\n",
        "\n",
        "    # TODO: Compute mean and max saliency values and print interpretation\n",
        "    print(\"  Interpretation: Higher values = more influential time steps.\")\n",
        "\n",
        "\n",
        "# TODO: Extract sequence length (SEQ_LEN) and input dimension (input_dim) from one batch of data\n",
        "\n",
        "# TODO: Define Transformer model architecture for saliency analysis\n",
        "# This version uses *all time steps* in the output layer.\n",
        "class TransformerForSaliency(nn.Module):\n",
        "    def __init__(self, input_dim, seq_len, d_model=64, nhead=4, num_layers=1, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        # TODO: Define embedding layer, transformer encoder, dropout, and output layer\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # TODO\n",
        "        pass\n",
        "\n",
        "\n",
        "# TODO: Initialize device, model, loss function, and optimizer\n",
        "# TODO: Train the model using the provided train_model() function\n",
        "\n",
        "# TODO: Generate and visualize the saliency map using the trained model\n",
        "\n",
        "# TODO: Print the analysis completion time\n",
        "# Example:\n",
        "# print(f\"\\nAnalysis completed at: {datetime.datetime.now().strftime('%I:%M %p CEST, %B %d, %Y')}\")\n"
      ],
      "metadata": {
        "id": "NsTeEQaVubTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot results"
      ],
      "metadata": {
        "id": "Yk2565tixSc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss_landscape(model, loader, criterion, device, steps=10, scale=0.01):\n",
        "    \"\"\"\n",
        "    Compute a 2D loss landscape around the model's current parameters.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # Get a small batch of data\n",
        "    x, y =\n",
        "\n",
        "    # Collect parameters\n",
        "    #TODO\n",
        "    # Flatten parameters for perturbation\n",
        "    #TODO\n",
        "    # Prepare loss grid\n",
        "    #TODO\n",
        "\n",
        "    for i, dx in enumerate(alphas):\n",
        "        for j, dy in enumerate(betas):\n",
        "            perturbed = base_params + dx * direction_x + dy * direction_y\n",
        "            idx = 0\n",
        "            for p in params:\n",
        "                numel = p.numel()\n",
        "                p.data = perturbed[idx:idx + numel].view_as(p).data.clone()\n",
        "                idx += numel\n",
        "\n",
        "            with torch.no_grad():\n",
        "                loss = criterion(model(x).squeeze(), y.squeeze()).item()\n",
        "                losses[i, j] = loss\n",
        "\n",
        "    # Restore original parameters\n",
        "    idx = 0\n",
        "    for p in params:\n",
        "        numel = p.numel()\n",
        "        p.data = base_params[idx:idx + numel].view_as(p).data.clone()\n",
        "        idx += numel\n",
        "\n",
        "    return losses\n",
        "\n",
        "\n",
        "def compute_tsne(model, loader, device, n_samples=100):\n",
        "    \"\"\"\n",
        "    Compute t-SNE projection of model embeddings.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    x, _ = next(iter(loader))\n",
        "    x = x[:n_samples].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # TODO: Extract embeddings or features from the model\n",
        "\n",
        "    # TODO: Initialize a t-SNE instance and fit_transform the features\n",
        "\n",
        "\n",
        "# Plot results\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "gs = fig.add_gridspec(3, 3)\n",
        "\n",
        "\n",
        "# Plot 1: Training MAE\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "# TODO\n",
        "\n",
        "# Plot 2: Test MAE (Generalization)\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "# TODO\n",
        "\n",
        "# Plot 3: Generalization Gap (Test - Train)\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "# TODO\n",
        "\n",
        "# Plot 4: Loss Landscape (Base Model)\n",
        "ax4 = fig.add_subplot(gs[1, :2])\n",
        "# TODO\n"
      ],
      "metadata": {
        "id": "FNAkAxGAxS8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Overfitting in the Base Model\n",
        "\n",
        "After plotting and analyzing the above visualizations for the base model, identify where **overfitting** occurs (refer to the results of the plots to highlight signs of overfitting) and provide reasons for this. Expand on this by pinpointing *where* and *why* overfitting occurs, with findings presented through **multiple visualizations** and **mathematically grounded reasoning**."
      ],
      "metadata": {
        "id": "xwaPgcAMZmjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BEST MODEL ANALYSIS: Performance vs. Generalization"
      ],
      "metadata": {
        "id": "N-emZVmcxYOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL RESULTS SUMMARY (ETTh1)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Method':<30} | {'Train MAE':<10} | {'Test MAE':<10} | {'Gap':<10} | {'Time (s)'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "\n",
        "# TODO: Loop through all models in 'results'\n",
        "#       Extract training MAE, test MAE, and total training time for each model\n",
        "#       Compute the final train/test MAE and the generalization gap (test - train)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BEST MODEL ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# TODO: Find the model with the lowest final Test MAE (best predictive performance)\n",
        "\n",
        "# TODO: Define a helper function to compute the generalization gap (test - train)\n",
        "# TODO: Use it to find the model with the smallest gap (best generalization)\n",
        "\n",
        "# TODO: Extract names and metrics of both models (best_test_model, best_gap_model)\n",
        "\n",
        "print(f\"Best Test MAE:      {best_test_name:<30} → {best_test_mae:.4f}\")\n",
        "print(f\" Smallest Gap:      {best_gap_name:<30} → {best_gap_value:.4f}\")\n",
        "\n",
        "if best_test_name == best_gap_name:\n",
        "    print(\"\\n This model achieves both the lowest prediction error and the best generalization!\")\n",
        "else:\n",
        "    print(f\"\\n Trade-off detected: The best-performing model ({best_test_name}) is not the most stable.\")\n",
        "    print(f\"   Consider your priority: raw accuracy vs. robustness to overfitting.\")\n",
        "\n",
        "print(f\"\\n Analysis completed at: {datetime.datetime.now().strftime('%I:%M %p CEST, %B %d, %Y')}\")\n"
      ],
      "metadata": {
        "id": "EX_6Z5oQxYxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploring the Limits of Dropout: Does More Regularization Always Help?"
      ],
      "metadata": {
        "id": "cHkGtqn-xbrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"EXPERIMENT 9: Dropout with Varying Rates\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "dropout_rates = [0.1, 0.3, 0.5, 0.7]\n",
        "\n",
        "results_dropout_vary = {}\n",
        "\n",
        "# TODO: Loop through each dropout rate\n",
        "for rate in dropout_rates:\n",
        "    print(f\"Dropout Rate: {rate}\")\n",
        "\n",
        "    # TODO: Initialize your Transformer model with the given dropout rate\n",
        "\n",
        "    # TODO: Define the loss function\n",
        "    # TODO: Define the optimizer\n",
        "\n",
        "    # TODO: Train the model\n"
      ],
      "metadata": {
        "id": "m-xvp651xcIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**  \n",
        "You have observed how the model’s performance changes as the dropout rate increases.  \n",
        "Under what specific conditions might higher dropout rates lead to worse generalization,  \n",
        "even though dropout is a regularization technique?  \n",
        "Explain the underlying reasons in terms of **bias**, **variance**, and **model capacity**."
      ],
      "metadata": {
        "id": "ch_QvTKNerxM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Questions"
      ],
      "metadata": {
        "id": "ZNnjggJ63j7x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. How does MAE (or loss) change with different dropout rates?\n",
        "\n"
      ],
      "metadata": {
        "id": "WfN5gYBU3k2R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <span style=\"color:cyan;\">**Answer:** Write your answer here</span>"
      ],
      "metadata": {
        "id": "NeVfZr7H3shp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. At which point does dropout start to hurt rather than help?"
      ],
      "metadata": {
        "id": "T-JOQ2bQ3s3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <span style=\"color:cyan;\">**Answer:** Write your answer here</span>"
      ],
      "metadata": {
        "id": "wXqSNRcT3v29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. What does this reveal about over-regularization in neural networks?"
      ],
      "metadata": {
        "id": "e9l54REy3wDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- <span style=\"color:cyan;\">**Answer:** Write your answer here</span>"
      ],
      "metadata": {
        "id": "qLEVX6hl4A6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ablation Study — Which Regularizer Helps Most?"
      ],
      "metadata": {
        "id": "x9NaelToxfNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_weight_stats(model):\n",
        "    # TODO: Compute L1 and L2 norms of model parameters and total number of parameters\n",
        "    # Return l1_norm, l2_norm, num_params\n",
        "    pass\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, train_loader, test_loader, epochs=10, l1_lambda=0.0, use_noise=False, noise_std=0.1):\n",
        "    # TODO: Initialize lists to store losses, MAEs, and times\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # TODO: Training phase\n",
        "        # - Set model to training mode\n",
        "        # - Add Gaussian noise if use_noise=True\n",
        "        # - Compute predictions, loss, and backpropagation\n",
        "        # - Add L1 regularization if l1_lambda > 0\n",
        "\n",
        "        # TODO: Evaluation phase\n",
        "        # - Set model to eval mode\n",
        "        # - Compute test loss and MAE without gradients\n",
        "        pass\n",
        "\n",
        "    # TODO: Compute L1/L2 norms and number of parameters using compute_weight_stats()\n",
        "    # TODO: Compute generalization gap (test MAE - train MAE)\n",
        "    # TODO: Return dictionary with training and evaluation statistics\n",
        "    pass\n",
        "\n",
        "\n",
        "# Ablation Results Container\n",
        "results = {}\n",
        "\n",
        "# Base Model\n",
        "print(\"Running: Base Model\")\n",
        "# TODO: Initialize base model and train\n",
        "\n",
        "# L1 Regularization\n",
        "print(\"Running: L1 Regularization\")\n",
        "# TODO: Initialize model and apply L1 regularization by setting l1_lambda > 0\n",
        "\n",
        "# L2 Regularization\n",
        "print(\"Running: L2 Regularization\")\n",
        "# TODO: Initialize model\n",
        "# TODO: Define optimizer with weight_decay (L2 regularization)\n",
        "# TODO: Train model and store results\n",
        "\n",
        "# Dropout Regularization\n",
        "print(\"Running: Dropout\")\n",
        "# TODO: Initialize model with dropout layers (e.g., dropout_rate=0.5)\n",
        "# TODO: Train and evaluate model\n",
        "\n",
        "# Batch Normalization\n",
        "print(\"Running: BatchNorm\")\n",
        "# TODO: Initialize model with batch normalization layers\n",
        "# TODO: Train and evaluate model\n",
        "\n",
        "# Early Stopping\n",
        "print(\"Running: Early Stopping\")\n",
        "# TODO: Implement early stopping mechanism\n",
        "# Hints:\n",
        "# - Track validation MAE\n",
        "# - Stop training when MAE doesn’t improve for several epochs (patience)\n",
        "# - Return final metrics and weight norms\n",
        "\n",
        "\n",
        "# Results Summary\n",
        "# TODO: Create a summary DataFrame comparing all models:\n",
        "#   - Train/Test MAE\n",
        "#   - Gap (Test - Train)\n",
        "#   - L1/L2 norms\n",
        "#   - Total time\n",
        "\n",
        "\n",
        "# TODO: Save results to CSV file (e.g., \"ablation_results.csv\")\n",
        "\n",
        "\n",
        "# Visualization Section\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# TODO: Plot 1 — Train/Test MAE curves for selected models\n",
        "# TODO: Plot 2 — Bar chart of generalization gaps\n",
        "# TODO: Plot 3 — L2 Norms of model weights\n",
        "# TODO: Save and display final plot\n"
      ],
      "metadata": {
        "id": "JuZUvUz_xfsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**  \n",
        "How do different regularization techniques (L1, L2, Dropout, BatchNorm, Early Stopping) affect the Transformer model’s performance in terms of **Mean Absolute Error (MAE)**, **generalization gap**, and **weight magnitudes**?\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ghMB84NapNh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Empirical Bias–Variance Decomposition: Quantifying the Impact of Each Regularizer"
      ],
      "metadata": {
        "id": "ggRSBdsUxkCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_single_model(model, train_loader, test_loader, device,\n",
        "                      epochs=10, l1_lambda=0.0, weight_decay=0.0):\n",
        "    \"\"\"\n",
        "    Trains a single model instance (used for bias-variance trials).\n",
        "    \"\"\"\n",
        "    # TODO: Move model to device\n",
        "    # TODO: Define loss function (MSE) and optimizer with given weight_decay\n",
        "    # TODO: Implement standard training loop for 'epochs' iterations\n",
        "    #       - Forward pass, compute loss\n",
        "    #       - Apply L1 regularization if l1_lambda > 0\n",
        "    #       - Backward pass and optimizer step\n",
        "    # Return trained model\n",
        "    pass\n",
        "\n",
        "\n",
        "def bias_variance_decomposition(\n",
        "    model_class,\n",
        "    model_kwargs,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    device,\n",
        "    n_trials=5,\n",
        "    epochs=10,\n",
        "    l1_lambda=0.0,\n",
        "    weight_decay=0.0,\n",
        "    dropout_rate=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Performs empirical bias-variance decomposition by training n_trials models.\n",
        "    Returns average bias^2, variance, and total error.\n",
        "    \"\"\"\n",
        "    # TODO: Initialize list to collect all predictions for each trial\n",
        "    # TODO: For each trial:\n",
        "    #   - Set manual random seeds for reproducibility\n",
        "    #   - Create model instance (include dropout_rate if provided)\n",
        "    #   - Train model\n",
        "    #   - Evaluate model on test set and store predictions and targets\n",
        "    # TODO: After all trials, compute:\n",
        "    #   - mean_predictions (average across models)\n",
        "    #   - bias^2 = (mean_predictions - true_targets)^2\n",
        "    #   - variance = variance of predictions across models\n",
        "    # TODO: Return average bias^2, variance, and total error\n",
        "    pass\n",
        "\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EMPIRICAL BIAS–VARIANCE DECOMPOSITION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "common_kwargs = {'input_dim': input_dim, 'd_model': 64, 'nhead': 4, 'num_layers': 1}\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "n_trials = 5\n",
        "epochs = 10\n",
        "\n",
        "bv_results = {}\n",
        "\n",
        "# 1. Base Model\n",
        "print(\"Running: Base Model\")\n",
        "# TODO: Run bias_variance_decomposition() for the base model\n",
        "\n",
        "# 2. L1 Regularization\n",
        "print(\"Running: L1 Regularization\")\n",
        "# TODO: Add L1 regularization by passing l1_lambda > 0\n",
        "\n",
        "# 3. L2 Regularization\n",
        "print(\"Running: L2 Regularization\")\n",
        "# TODO: Add L2 regularization by setting weight_decay > 0\n",
        "\n",
        "# 4. Dropout\n",
        "print(\"Running: Dropout\")\n",
        "# TODO: Use a dropout-enabled Transformer model (e.g., dropout_rate=0.5)\n",
        "\n",
        "# 5. BatchNorm\n",
        "print(\"Running: BatchNorm\")\n",
        "# TODO: Use a Transformer model with Batch Normalization layers\n",
        "\n",
        "\n",
        "# RESULTS SUMMARY\n",
        "# TODO: Collect bias^2, variance, and total error for each model into a DataFrame\n",
        "\n",
        "# TODO: Save summary results to CSV\n",
        "\n",
        "# INSIGHT CALCULATION\n",
        "# TODO: Compute relative variance reduction and bias change compared to Base Model\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVQlixj0xkXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**  \n",
        "How do different **regularization techniques** affect the **bias, variance, and total error** of a base model?  \n",
        "Analyze the **bias-variance decomposition** for L1, L2, Dropout, and BatchNorm regularization."
      ],
      "metadata": {
        "id": "Y1OKJzVkrKBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Empirical Analysis of Generalization Gap Scaling with Model Complexity"
      ],
      "metadata": {
        "id": "II9A00ntxndn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_for_complexity(model_kwargs, train_loader, test_loader, device, epochs=10):\n",
        "    \"\"\"\n",
        "    Trains a base model (no regularization) with the given architecture.\n",
        "    Returns final train/test MAE and full learning curves.\n",
        "    \"\"\"\n",
        "    # TODO: Initialize TransformerBaseModel using model_kwargs and move to device\n",
        "    # TODO: Define loss function  and optimizer\n",
        "\n",
        "    train_maes, test_maes = [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # TODO\n",
        "        pass\n",
        "\n",
        "        # TODO: Evaluate model on test_loader in eval() mode\n",
        "        pass\n",
        "\n",
        "    # TODO: Return dictionary with 'train_maes', 'test_maes', and final results\n",
        "    pass\n",
        "\n",
        "\n",
        "#Experiment 1: Vary model depth (number of layers)\n",
        "print(\"=\" * 80)\n",
        "print(\"GENERALIZATION GAP vs MODEL COMPLEXITY (num_layers)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "epochs = 10\n",
        "\n",
        "num_layers_list = [1, 2, 3, 4, 5]\n",
        "complexity_results = {}\n",
        "\n",
        "for num_layers in num_layers_list:\n",
        "    print(f\"Training model with num_layers = {num_layers}\")\n",
        "    model_kwargs = {\n",
        "        'input_dim': input_dim,\n",
        "        'd_model': 64,\n",
        "        'nhead': 4,\n",
        "        'num_layers': num_layers\n",
        "    }\n",
        "    # TODO: Call train_model_for_complexity() and save results\n",
        "    pass\n",
        "\n",
        "\n",
        "#Experiment 2: Vary model width (d_model)\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"GENERALIZATION GAP vs MODEL COMPLEXITY (d_model)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "d_model_list = [16, 32, 64, 128, 256]\n",
        "complexity_results_d = {}\n",
        "\n",
        "for d_model in d_model_list:\n",
        "    print(f\"Training model with d_model = {d_model}\")\n",
        "    model_kwargs = {\n",
        "        'input_dim': input_dim,\n",
        "        'd_model': d_model,\n",
        "        'nhead': min(4, d_model // 8),\n",
        "        'num_layers': 1\n",
        "    }\n",
        "    # TODO: Train model with different embedding size and store results\n",
        "    pass\n",
        "\n",
        "\n",
        "# PLOTTING AND SAVING RESULTS\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "# (a) Generalization gap vs. number of layers\n",
        "plt.subplot(1, 2, 1)\n",
        "layers = list(complexity_results.keys())\n",
        "gaps_layers = [complexity_results[l]['gap'] for l in layers]\n",
        "train_maes_layers = [complexity_results[l]['final_train_mae'] for l in layers]\n",
        "test_maes_layers = [complexity_results[l]['final_test_mae'] for l in layers]\n",
        "\n",
        "plt.plot(layers, train_maes_layers, 'o--', label='Train MAE')\n",
        "plt.plot(layers, test_maes_layers, 's--', label='Test MAE')\n",
        "plt.plot(layers, gaps_layers, 'd-', color='red', label='Generalization Gap')\n",
        "plt.xlabel('Number of Transformer Layers')\n",
        "plt.ylabel('MAE / Gap')\n",
        "plt.title('Generalization Gap vs Model Depth')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# (b) Generalization gap vs. embedding size (d_model)\n",
        "plt.subplot(1, 2, 2)\n",
        "d_models = list(complexity_results_d.keys())\n",
        "gaps_d = [complexity_results_d[d]['gap'] for d in d_models]\n",
        "train_maes_d = [complexity_results_d[d]['final_train_mae'] for d in d_models]\n",
        "test_maes_d = [complexity_results_d[d]['final_test_mae'] for d in d_models]\n",
        "\n",
        "plt.plot(d_models, train_maes_d, 'o--', label='Train MAE')\n",
        "plt.plot(d_models, test_maes_d, 's--', label='Test MAE')\n",
        "plt.plot(d_models, gaps_d, 'd-', color='red', label='Generalization Gap')\n",
        "plt.xlabel('d_model (Embedding Size)')\n",
        "plt.ylabel('MAE / Gap')\n",
        "plt.title('Generalization Gap vs Model Width')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"generalization_gap_vs_complexity.png\", dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# TODO: Save results as CSVs after computing them"
      ],
      "metadata": {
        "id": "jqN0eanMxnyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:**  \n",
        "How does the **generalization gap** (*Test MAE - Train MAE*) change as the **complexity of a Transformer model** varies?  \n",
        "Specifically, analyze the impact of:\n",
        "\n",
        "- **Model Depth:** Number of Transformer layers  \n",
        "- **Model Width:** Embedding size (`d_model`)  \n",
        "\n",
        "What trends are observed in training performance, test performance, and overfitting risk across different configurations?\n"
      ],
      "metadata": {
        "id": "UD1Nyb5_qYyq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAn5f6BNqf3N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}